# ğŸ¥ Stroke Conversation Bot

A local AI conversation bot for stroke patient follow-up assessments using Ollama for local LLM processing and real-time voice interaction.

## âœ¨ Features

- **ğŸ¤– Local AI Processing**: Uses Ollama for completely local LLM processing
- **ğŸ™ï¸ Real-time Voice**: Voice conversation with speech-to-text and text-to-speech
- **ğŸ“‹ Structured Assessment**: Follows medical assessment protocols from YAML configuration
- **ğŸ”’ Privacy-First**: All processing happens locally, no external API calls
- **ğŸ“Š Data Export**: Export conversations in JSON, CSV formats
- **ğŸ¯ Medical-Focused**: Specialized for stroke patient follow-up care
- **âš¡ Real-time Recording**: Automatic conversation recording and transcription

## ğŸ—ï¸ Architecture

```
stroke_bot/
â”œâ”€â”€ conversation_engine/     # Core conversation logic
â”‚   â”œâ”€â”€ yaml_parser.py      # Parse stroke_sen1.yml
â”‚   â”œâ”€â”€ state_machine.py    # Conversation state management
â”‚   â”œâ”€â”€ prompt_generator.py # Generate AI prompts
â”‚   â””â”€â”€ conversation_flow.py # Main flow orchestration
â”œâ”€â”€ extensions/
â”‚   â””â”€â”€ ollama_medical/     # Ollama LLM integration
â”‚       â”œâ”€â”€ ollama_client.py
â”‚       â”œâ”€â”€ medical_llm.py
â”‚       â””â”€â”€ conversation_memory.py
â”œâ”€â”€ recording/              # Audio recording & transcription
â”‚   â”œâ”€â”€ audio_recorder.py
â”‚   â”œâ”€â”€ transcriber.py
â”‚   â”œâ”€â”€ conversation_storage.py
â”‚   â””â”€â”€ recording_manager.py
â”œâ”€â”€ config/                 # Configuration files
â”œâ”€â”€ scripts/               # Utility scripts
â””â”€â”€ main.py               # Main application
```

## ğŸš€ Quick Start

### Prerequisites

- **Conda Environment**: `vten` (already created)
- **Ollama**: Installed and running
- **Python 3.10+**: In the conda environment
- **Audio Hardware**: Microphone and speakers

### Installation

1. **Activate the conda environment**:
   ```bash
   conda activate vten
   ```

2. **Run the setup script**:
   ```bash
   cd stroke_bot
   ./setup.sh
   ```

3. **Test the installation**:
   ```bash
   python scripts/test_conversation.py
   ```

### Basic Usage

**Interactive Mode**:
```bash
python main.py --interactive --patient-name "John Doe" --honorific "Mr."
```

**API Mode**:
```bash
python main.py --patient-name "John Doe" --honorific "Mr."
```

## ğŸ“‹ Usage Examples

### Start a Conversation

```bash
# Interactive mode with a patient
python main.py --interactive --patient-name "Jane Smith" --honorific "Ms."

# Test mode (components only)
python main.py --test
```

### Export Data

```bash
# List recent conversations
python scripts/export_data.py list --limit 20

# Export specific conversation
python scripts/export_data.py conversation <conversation_id> --format json

# Export patient data
python scripts/export_data.py patient "John Doe" --format csv

# Export by date range
python scripts/export_data.py date-range 2024-01-01 2024-01-31 --format json

# Show storage statistics
python scripts/export_data.py stats
```

## âš™ï¸ Configuration

### Main Configuration

Edit `config/stroke_bot_config.yaml`:

```yaml
bot:
  name: "AI Stroke Navigator"
  organization: "PennState Health"
  site: "Hershey Medical Center"

conversation:
  yaml_file: "../stroke_sen1.yml"
  max_duration_minutes: 30
  emergency_keywords: ["emergency", "911", "urgent", "help"]

llm:
  provider: "ollama"
  model: "llama3.2:3b"
  temperature: 0.7
  max_tokens: 512

audio:
  sample_rate: 16000
  recording_path: "data/recordings"
  transcription_path: "data/transcriptions"
```

### Ollama Models

The setup script automatically downloads recommended models:

- **llama3.2:3b** (recommended for medical conversations)
- **mistral:7b** (alternative option)
- **phi3:mini** (for testing)

## ğŸ¯ Conversation Flow

The bot follows a structured assessment based on `stroke_sen1.yml`:

1. **Greeting & Consent** - Introduction and consent verification
2. **Knowledge Check** - Understanding of ischemic stroke
3. **General Well-Being** - Overall health assessment
4. **Medications** - Medication adherence and side effects
5. **Follow-up Care** - Appointment scheduling and rehabilitation
6. **Lifestyle Management** - Diet, activity, and risk factors
7. **Daily Activities** - ADL support and home safety
8. **Resources** - Support systems and next steps
9. **Wrap-up** - Summary and emergency instructions

## ğŸ”§ Advanced Usage

### Custom Models

Switch to different Ollama models:

```python
from extensions.ollama_medical import MedicalLLM, OllamaConfig

config = OllamaConfig(model="mistral:7b", temperature=0.6)
medical_llm = MedicalLLM(config)
```

### Custom Conversation Flow

Modify `stroke_sen1.yml` to customize the conversation:

```yaml
flow:
  - key: custom_question
    type: free
    prompt: "Your custom question here"
    section: "Custom Section"
```

### Recording Configuration

Adjust audio settings:

```python
from recording import AudioRecorder

recorder = AudioRecorder(
    sample_rate=44100,  # Higher quality
    channels=2,         # Stereo
    chunk_size=2048     # Larger chunks
)
```

## ğŸ“Š Data Management

### Storage Structure

```
data/
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ conversations.db    # SQLite database
â”œâ”€â”€ recordings/             # Audio files (.wav)
â”œâ”€â”€ transcriptions/         # Text files (.txt)
â””â”€â”€ exports/               # Exported data
```

### Database Schema

- **conversations**: Main conversation records
- **responses**: Individual question responses
- **audio_segments**: Audio file segments with timestamps

### Export Formats

- **JSON**: Complete conversation data with metadata
- **CSV**: Tabular format for analysis
- **Excel**: Formatted reports (future)

## ğŸ› ï¸ Development

### Project Structure

```
stroke_bot/
â”œâ”€â”€ conversation_engine/    # Core conversation logic
â”œâ”€â”€ extensions/            # LLM and external integrations
â”œâ”€â”€ recording/             # Audio and data management
â”œâ”€â”€ config/               # Configuration files
â”œâ”€â”€ scripts/              # Utility and test scripts
â”œâ”€â”€ data/                 # Runtime data storage
â””â”€â”€ logs/                 # Application logs
```

### Testing

Run comprehensive tests:

```bash
# Test all components
python scripts/test_conversation.py

# Test specific component
python -c "from conversation_engine import ConversationFlow; print('âœ… OK')"
```

### Logging

Logs are written to:
- Console output (INFO level)
- `logs/stroke_bot.log` (DEBUG level)
- `logs/error.log` (ERROR level)

## ğŸ”’ Privacy & Security

- **Local Processing**: All AI processing happens locally
- **No External APIs**: No data sent to external services
- **Encrypted Storage**: Database and files are stored locally
- **HIPAA Compliant**: Designed for healthcare data privacy
- **Audit Trail**: Complete conversation logging

## ğŸš¨ Emergency Handling

The bot automatically detects emergency keywords:

- "emergency", "911", "urgent", "help"
- "chest pain", "can't breathe", "can't speak"
- "numb", "paralyzed", "stroke symptoms"

When detected, the bot immediately:
1. Stops the conversation
2. Provides emergency instructions
3. Logs the emergency event
4. Saves the conversation for review

## ğŸ“ˆ Performance

### System Requirements

- **CPU**: 2+ cores (4+ recommended)
- **RAM**: 4GB+ (8GB+ recommended for larger models)
- **Storage**: 10GB+ for models and data
- **Audio**: Microphone and speakers

### Optimization

- Use smaller models (llama3.2:3b) for faster responses
- Adjust audio chunk size for latency vs. quality
- Enable audio compression for storage efficiency

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details.

## ğŸ†˜ Support

### Common Issues

**Ollama not responding**:
```bash
# Check if Ollama is running
ollama list

# Start Ollama service
ollama serve
```

**Audio not working**:
```bash
# Test audio input
python -c "import pyaudio; print('Audio OK')"

# Check microphone permissions
```

**Model not found**:
```bash
# Pull the model
ollama pull llama3.2:3b

# List available models
ollama list
```

### Getting Help

1. Check the logs in `logs/stroke_bot.log`
2. Run the test script: `python scripts/test_conversation.py`
3. Check Ollama status: `ollama list`
4. Verify audio hardware

## ğŸ‰ Success!

You now have a fully functional stroke conversation bot that:

âœ… Runs completely locally with Ollama  
âœ… Follows medical assessment protocols  
âœ… Records and transcribes conversations  
âœ… Exports data in multiple formats  
âœ… Handles emergency situations  
âœ… Maintains patient privacy  

**Ready to start your first conversation!** ğŸ¥ğŸ¤–
