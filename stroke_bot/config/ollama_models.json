{
  "primary_model": "llama3.2:3b",
  "alternative_models": ["mistral:7b", "phi3:mini"],
  "model_configs": {
    "llama3.2:3b": {
      "temperature": 0.7,
      "top_p": 0.9,
      "max_tokens": 512,
      "context_length": 4096
    },
    "mistral:7b": {
      "temperature": 0.6,
      "top_p": 0.9,
      "max_tokens": 1024,
      "context_length": 8192
    },
    "phi3:mini": {
      "temperature": 0.8,
      "top_p": 0.9,
      "max_tokens": 256,
      "context_length": 2048
    }
  }
}
